{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Rahmanda Afebrio Yuris Soesatyo - Chapter 14:,Deep Computer Vision Using Convolutional Neural Networks"
      ],
      "metadata": {
        "id": "JHJ3_NWclcxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Convolutional and Pooling Layers\n",
        "\n",
        "Convolutional layer adalah blok utama CNN: neuron tidak lagi terhubung ke seluruh piksel gambar, tetapi hanya ke area lokal kecil yang disebut receptive field. Dengan menggeser receptive field ini di seluruh input, layer pertama mempelajari fitur rendah (tepi, garis), dan layer berikutnya mengkombinasikan fitur ini menjadi pola yang lebih kompleks (sudut, tekstur, objek), membentuk hierarki representasi visual.​\n",
        "\n",
        "Setiap filter (kernel) adalah matriks bobot kecil yang jika diaplikasikan ke gambar akan menghasilkan feature map yang menonjolkan pola tertentu (misalnya garis vertikal atau horizontal). Banyak filter dalam satu layer menghasilkan banyak feature map, dan parameter sharing (bobot filter yang sama dipakai di semua lokasi) sangat mengurangi jumlah parameter serta membuat model translationally equivariant (pola yang sama dikenali di lokasi berbeda).​\n",
        "\n",
        "Pooling layer (umumnya MaxPool2D) melakukan subsampling dengan mengambil agregasi (max atau mean) dari patch lokal (misal 2×2) untuk mengurangi resolusi spasial, komputasi, dan sedikit meningkatkan invariansi terhadap translasi kecil. Pooling bisa dilakukan per-channel (umum) maupun depthwise (untuk belajar invariansi terhadap variasi seperti rotasi atau warna)."
      ],
      "metadata": {
        "id": "fHI7FRJHlkua"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3lrf6Ufla8y",
        "outputId": "0aac3efc-e502-4761-f2c9-2d2d05850b67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Simple conv + pooling block\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(\n",
        "        filters=32, kernel_size=3, strides=1,\n",
        "        padding=\"same\", activation=\"relu\",\n",
        "        input_shape=[28, 28, 1]          # grayscale MNIST-like\n",
        "    ),\n",
        "    keras.layers.MaxPool2D(pool_size=2),  # halve H and W\n",
        "    keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.MaxPool2D(2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\"),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. A Typical CNN for Image Classification\n",
        "\n",
        "Arsitektur CNN klasik menumpuk beberapa blok Conv2D(+ReLU) lalu MaxPool2D, diakhiri dengan flatten dan beberapa Dense layer untuk klasifikasi. Resolusi spasial berkurang bertahap (karena stride/pooling), sedangkan kedalaman (jumlah feature maps) biasanya meningkat, karena kombinasi fitur rendah menghasilkan banyak kombinasi fitur tinggi.​\n",
        "\n",
        "Contoh pada Fashion MNIST: pertama Conv besar (64 filter 7×7) diikuti pooling, lalu blok conv berturut-turut dengan jumlah filter bertambah (128, 256) dan pooling, kemudian dua Dense layer dengan dropout dan output softmax. Model semacam ini mencapai akurasi > 92% di Fashion MNIST, jauh lebih baik daripada MLP murni."
      ],
      "metadata": {
        "id": "o9Kw3Q9hlrWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(\n",
        "        64, 7, activation=\"relu\", padding=\"same\",\n",
        "        input_shape=[28, 28, 1]\n",
        "    ),\n",
        "    keras.layers.MaxPool2D(2),\n",
        "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.MaxPool2D(2),\n",
        "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.MaxPool2D(2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=\"sgd\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "metadata": {
        "id": "FBi2HdIelvU5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Modern CNN Architectures (LeNet, AlexNet, GoogLeNet, ResNet, Xception, SENet)\n",
        "\n",
        "Perkembangan arsitektur Convolutional Neural Networks (CNN) modern sangat dipacu oleh kompetisi ImageNet Large Scale Visual Recognition Challenge (ILSVRC), yang mendorong desain jaringan semakin dalam, efisien, dan akurat.\n",
        "\n",
        "LeNet-5 (1998)\n",
        "Merupakan CNN klasik yang dikembangkan untuk pengenalan digit MNIST. Arsitekturnya relatif kecil dan dangkal, terdiri dari convolution layer, average pooling, dan beberapa fully connected layer. Meskipun sederhana, LeNet sudah memperkenalkan konsep penting seperti local receptive fields dan weight sharing.\n",
        "\n",
        "AlexNet (2012)\n",
        "Menandai terobosan besar dalam deep learning untuk visi komputer. AlexNet jauh lebih dalam dan lebar dibanding LeNet, serta memperkenalkan penggunaan ReLU, dropout, data augmentation, dan local response normalization (LRN). Model ini secara drastis mengungguli metode lain di ImageNet dan memicu kebangkitan deep CNN.\n",
        "\n",
        "GoogLeNet / Inception (2014)\n",
        "Memperkenalkan Inception module, yaitu struktur paralel yang mengombinasikan convolution 1×1, 3×3, 5×5, dan max-pooling dalam satu blok. Penggunaan 1×1 convolution sebagai bottleneck membuat model sangat dalam namun tetap efisien secara parameter.\n",
        "\n",
        "ResNet (2015)\n",
        "Mengatasi masalah degradasi performa pada jaringan sangat dalam dengan memperkenalkan residual connections berbentuk skip connection (x + F(x)). Konsep residual learning memungkinkan pelatihan jaringan dengan ratusan bahkan ribuan layer secara stabil dan efektif.\n",
        "\n",
        "Xception (2016)\n",
        "Merupakan ekstremisasi dari Inception dengan mengganti modulnya menggunakan depthwise separable convolutions, yang memisahkan pemrosesan spasial dan lintas-channel. Pendekatan ini meningkatkan efisiensi komputasi dan sering memberikan akurasi lebih baik pada dataset besar.\n",
        "\n",
        "SENet (2017)\n",
        "Menambahkan Squeeze-and-Excitation (SE) blocks ke dalam arsitektur CNN seperti ResNet atau Inception. Blok ini melakukan feature map recalibration dengan memodelkan dependensi antar-channel menggunakan konteks global, sehingga meningkatkan performa secara signifikan."
      ],
      "metadata": {
        "id": "lZmXocwVlwUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "class ResidualUnit(keras.layers.Layer):\n",
        "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        self.main_layers = [\n",
        "            keras.layers.Conv2D(filters, 3, strides=strides,\n",
        "                                padding=\"same\", use_bias=False),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            self.activation,\n",
        "            keras.layers.Conv2D(filters, 3, strides=1,\n",
        "                                padding=\"same\", use_bias=False),\n",
        "            keras.layers.BatchNormalization(),\n",
        "        ]\n",
        "        self.skip_layers = []\n",
        "        if strides > 1:\n",
        "            self.skip_layers = [\n",
        "                keras.layers.Conv2D(filters, 1, strides=strides,\n",
        "                                    padding=\"same\", use_bias=False),\n",
        "                keras.layers.BatchNormalization(),\n",
        "            ]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z = inputs\n",
        "        for layer in self.main_layers:\n",
        "            z = layer(z)\n",
        "        skip_z = inputs\n",
        "        for layer in self.skip_layers:\n",
        "            skip_z = layer(skip_z)\n",
        "        return self.activation(z + skip_z)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Conv2D(\n",
        "    64, 7, strides=2, padding=\"same\",\n",
        "    use_bias=False, input_shape=[224, 224, 3]\n",
        "))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\"))\n",
        "\n",
        "prev_filters = 64\n",
        "for filters in [64]*3 + [128]*4 + [256]*6 + [512]*3:\n",
        "    strides = 1 if filters == prev_filters else 2\n",
        "    model.add(ResidualUnit(filters, strides=strides))\n",
        "    prev_filters = filters\n",
        "\n",
        "model.add(keras.layers.GlobalAvgPool2D())\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "nvQfFX-qlz8i"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Data Augmentation and Transfer Learning for Image Classification\n",
        "\n",
        "Data augmentation bertujuan memperbesar dataset training secara artifisial dengan menghasilkan variasi realistis dari gambar asli, seperti:\n",
        "\n",
        "rotasi kecil,\n",
        "translasi dan zoom,\n",
        "flip horizontal,\n",
        "perubahan brightness atau kontras.\n",
        "Teknik ini bertindak sebagai regularizer, karena memaksa model mempelajari representasi yang lebih invariant terhadap transformasi yang tidak mengubah label kelas.\n",
        "\n",
        "Transfer Learning\n",
        "Untuk tugas visi komputer yang kompleks dan dataset terbatas, pendekatan yang umum adalah transfer learning, yaitu:\n",
        "\n",
        "Menggunakan CNN besar yang telah dilatih di ImageNet (misalnya ResNet-50, Xception) sebagai feature extractor.\n",
        "Mengganti classifier di bagian atas dengan head baru (biasanya Global Average Pooling + Dense).\n",
        "Melatih top layers terlebih dahulu.\n",
        "Melakukan fine-tuning sebagian atau seluruh base model dengan learning rate kecil.\n",
        "Strategi ini secara signifikan mempercepat training dan meningkatkan performa."
      ],
      "metadata": {
        "id": "pExqfUnBl3RG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "n_classes = 5  # contoh\n",
        "\n",
        "base_model = keras.applications.xception.Xception(\n",
        "    weights=\"imagenet\", include_top=False\n",
        ")\n",
        "\n",
        "# Freeze base at first\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "output = keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
        "model = keras.Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.2, momentum=0.9, decay=0.01)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    image = keras.applications.xception.preprocess_input(image)\n",
        "    return image, label\n",
        "\n",
        "batch_size = 32\n",
        "train_set = train_set.shuffle(1000).map(preprocess).batch(batch_size).prefetch(1)\n",
        "valid_set = valid_set.map(preprocess).batch(batch_size).prefetch(1)\n",
        "\n",
        "history = model.fit(train_set, epochs=5, validation_data=valid_set)\n",
        "\n",
        "# Fine-tune: unfreeze base with smaller learning rate\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, decay=0.001)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history_fine = model.fit(train_set, epochs=10, validation_data=valid_set)\n"
      ],
      "metadata": {
        "id": "KFAonO5el7sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Detection, Localization, and Segmentation\n",
        "\n",
        "Selain klasifikasi gambar, CNN juga digunakan untuk berbagai tugas visi tingkat lanjut.\n",
        "\n",
        "Classification + Localization\n",
        "Model memprediksi kelas objek sekaligus koordinat bounding box (biasanya empat nilai ter-normalisasi). Evaluasi sering menggunakan metrik Intersection over Union (IoU) dan variasi mean Average Precision (mAP).\n",
        "\n",
        "Object Detection\n",
        "Bertujuan mendeteksi banyak objek dalam satu gambar. Pendekatan klasik menggunakan sliding window dan CNN, namun metode modern berbasis Fully Convolutional Networks (FCN) seperti YOLO dan SSD mampu memprediksi banyak bounding box dan kelas sekaligus dalam satu forward pass, sehingga jauh lebih efisien.\n",
        "\n",
        "Semantic Segmentation\n",
        "Mengklasifikasikan setiap piksel dalam gambar (misalnya jalan, kendaraan, pejalan kaki). Umumnya menggunakan arsitektur encoder–decoder, di mana CNN bertindak sebagai encoder, lalu decoder melakukan upsampling (transposed convolution) dengan bantuan skip connections untuk memulihkan resolusi spasial."
      ],
      "metadata": {
        "id": "48HdsZbHl8T1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Suppose 'cnn' is a conv backbone that outputs feature maps of shape [7, 7, 512]\n",
        "backbone_output = keras.layers.Input(shape=[7, 7, 512])\n",
        "\n",
        "# Dense(10) equivalent: Conv2D with 10 filters of size 7x7, valid padding\n",
        "logits = keras.layers.Conv2D(\n",
        "    filters=10, kernel_size=7, strides=1, padding=\"valid\"\n",
        ")(backbone_output)  # output shape: [1, 1, 10]\n",
        "\n",
        "# If we feed a larger image, backbone_output becomes [H', W', 512],\n",
        "# and logits becomes [H'-6, W'-6, 10] => grid of predictions (detection-like)\n",
        "fcn_model = keras.Model(inputs=backbone_output, outputs=logits)\n"
      ],
      "metadata": {
        "id": "lGxa-JC-mAEQ"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}