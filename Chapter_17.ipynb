{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Rahmanda Afebrio Yuris Soesatyo - Chapter 17:Representation Learning and Generative Learning Using Autoencoders and GANs"
      ],
      "metadata": {
        "id": "sz2MECu5opqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Undercomplete and Stacked Autoencoders\n",
        "\n",
        "Autoencoder adalah model neural network yang terdiri dari encoder dan decoder, di mana encoder memampatkan input ke dalam representasi laten, sementara decoder bertugas merekonstruksi kembali input dari representasi tersebut. Pada undercomplete autoencoder, ukuran latent code dibuat lebih kecil dari dimensi input, sehingga model “dipaksa” mempelajari fitur-fitur paling penting agar rekonstruksi tetap mendekati data asli, biasanya dengan meminimalkan reconstruction loss seperti Mean Squared Error atau binary cross-entropy.\n",
        "\n",
        "Jika digunakan aktivasi linear dan loss MSE, undercomplete autoencoder pada dasarnya akan berperilaku mirip dengan Principal Component Analysis (PCA), karena sama-sama mencari representasi berdimensi lebih rendah yang menangkap variansi utama data. Namun, keunggulan autoencoder muncul ketika arsitekturnya diperluas menjadi stacked autoencoder, yaitu encoder–decoder berlapis dengan struktur simetris, yang memungkinkan pemodelan hubungan nonlinier yang tidak dapat ditangkap oleh PCA.\n",
        "\n",
        "Dalam praktik, stacked autoencoder sering digunakan untuk reduksi dimensi—misalnya sebagai tahap awal sebelum visualisasi data dengan t-SNE—serta untuk unsupervised pretraining. Pendekatan ini sangat berguna ketika data berlabel terbatas, karena model dapat terlebih dahulu belajar representasi umum dari data sebelum di-fine-tune lebih lanjut untuk tugas supervised seperti klasifikasi atau regresi."
      ],
      "metadata": {
        "id": "GR1rmhweo0hz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTvnTstjoec_"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Linear autoencoder 3D -> 2D (PCA-like)\n",
        "encoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(2, input_shape=[3])        # no activation\n",
        "])\n",
        "decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(3, input_shape=[2])        # no activation\n",
        "])\n",
        "autoencoder = keras.models.Sequential([encoder, decoder])\n",
        "autoencoder.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=0.1))\n",
        "history = autoencoder.fit(X_train, X_train, epochs=20)\n",
        "codings = encoder.predict(X_train)\n",
        "\n",
        "# Stacked autoencoder for Fashion MNIST\n",
        "stacked_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(30, activation=\"selu\"),\n",
        "])\n",
        "stacked_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28]),\n",
        "])\n",
        "stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
        "stacked_ae.compile(loss=\"binary_crossentropy\",\n",
        "                   optimizer=keras.optimizers.SGD(learning_rate=1.5))\n",
        "history = stacked_ae.fit(X_train, X_train, epochs=10,\n",
        "                         validation_data=(X_valid, X_valid))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Variants: Convolutional, Recurrent, Denoising, and Sparse Autoencoders\n",
        "\n",
        "Berbagai varian autoencoder dikembangkan untuk menyesuaikan diri dengan karakteristik data yang berbeda-beda. Perbedaan ini terutama terletak pada jenis layer yang digunakan dan tujuan tambahan yang ingin dicapai selama proses pembelajaran representasi.\n",
        "\n",
        "Convolutional autoencoder dirancang khusus untuk data citra dengan mengganti layer Dense menjadi convolution dan transposed convolution. Encoder menurunkan resolusi spasial sambil memperkaya jumlah channel, sedangkan decoder membalik proses tersebut untuk merekonstruksi gambar. Dengan cara ini, struktur spasial citra tetap terjaga dan jumlah parameter menjadi jauh lebih efisien dibanding autoencoder berbasis fully connected.\n",
        "\n",
        "Untuk data sekuens seperti time series atau teks, recurrent autoencoder memanfaatkan RNN, LSTM, atau GRU. Encoder bertugas merangkum seluruh urutan menjadi satu representasi vektor, sementara decoder mengubah vektor tersebut kembali menjadi urutan. Biasanya, representasi laten diulang ke setiap langkah waktu menggunakan mekanisme seperti RepeatVector agar decoder dapat menghasilkan kembali sekuens input secara lengkap.\n",
        "\n",
        "Denoising autoencoder dilatih dengan memberikan input yang telah ditambahkan noise, lalu meminta model merekonstruksi versi data yang bersih. Pendekatan ini mendorong model untuk belajar fitur yang lebih robust dan stabil terhadap gangguan, sehingga sering digunakan pada tugas image denoising sekaligus sebagai bentuk regularisasi representasi.\n",
        "\n",
        "Sementara itu, sparse autoencoder menambahkan kendala sparsity pada aktivasi latent code, misalnya melalui regularisasi ℓ1 atau KL divergence terhadap tingkat aktivasi tertentu. Akibatnya, hanya sebagian kecil neuron yang aktif pada satu waktu, sehingga setiap neuron cenderung merepresentasikan fitur yang lebih spesifik dan bermakna. Secara keseluruhan, berbagai varian autoencoder ini menjadi fondasi penting dalam pembelajaran representasi tak terawasi dan banyak digunakan dalam pretraining, denoising, serta reduksi dimensi nonlinier."
      ],
      "metadata": {
        "id": "CNzgFpFno4Ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "# Conv autoencoder (Fashion MNIST)\n",
        "conv_encoder = keras.models.Sequential([\n",
        "    keras.layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n",
        "    keras.layers.Conv2D(16, 3, padding=\"same\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(2),\n",
        "    keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(2),\n",
        "    keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(2),\n",
        "])\n",
        "conv_decoder = keras.models.Sequential([\n",
        "    keras.layers.Conv2DTranspose(32, 3, strides=2, padding=\"valid\",\n",
        "                                 activation=\"selu\", input_shape=[3, 3, 64]),\n",
        "    keras.layers.Conv2DTranspose(16, 3, strides=2, padding=\"same\",\n",
        "                                 activation=\"selu\"),\n",
        "    keras.layers.Conv2DTranspose(1, 3, strides=2, padding=\"same\",\n",
        "                                 activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28]),\n",
        "])\n",
        "conv_ae = keras.models.Sequential([conv_encoder, conv_decoder])\n",
        "\n",
        "# Recurrent autoencoder (treat image as 28×(sequence of 28 pixels))\n",
        "recurrent_encoder = keras.models.Sequential([\n",
        "    keras.layers.LSTM(100, return_sequences=True, input_shape=[None, 28]),\n",
        "    keras.layers.LSTM(30),\n",
        "])\n",
        "recurrent_decoder = keras.models.Sequential([\n",
        "    keras.layers.RepeatVector(28, input_shape=[30]),\n",
        "    keras.layers.LSTM(100, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(\n",
        "        keras.layers.Dense(28, activation=\"sigmoid\")\n",
        "    ),\n",
        "])\n",
        "recurrent_ae = keras.models.Sequential([recurrent_encoder, recurrent_decoder])\n",
        "\n",
        "# Denoising AE via Dropout\n",
        "dropout_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(30, activation=\"selu\"),\n",
        "])\n",
        "dropout_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28]),\n",
        "])\n",
        "dropout_ae = keras.models.Sequential([dropout_encoder, dropout_decoder])\n",
        "\n",
        "# Sparse AE with L1 activity regularization\n",
        "sparse_l1_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(300, activation=\"sigmoid\"),\n",
        "    keras.layers.ActivityRegularization(l1=1e-3),\n",
        "])\n",
        "sparse_l1_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[300]),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28]),\n",
        "])\n",
        "sparse_l1_ae = keras.models.Sequential([sparse_l1_encoder, sparse_l1_decoder])\n"
      ],
      "metadata": {
        "id": "8q6SkBKvpCOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Sparse Autoencoders with KL Divergence and Variational Autoencoders\n",
        "\n",
        "\n",
        "Pendekatan sparsity yang lebih fleksibel dapat dicapai dengan menambahkan KL divergence sebagai regularisasi antara tingkat sparsity target ( p ) dan rata-rata aktivasi aktual ( q ) dari setiap neuron pada latent code. Regularizer ini mendorong agar nilai aktivasi rata-rata tiap neuron mendekati ( p ) (misalnya 0.05–0.1), sehingga sebagian besar neuron tetap tidak aktif dan hanya merespons ketika fitur tertentu muncul. Dibandingkan regularisasi ℓ1 sederhana, metode ini memberikan kontrol yang lebih eksplisit terhadap distribusi aktivasi neuron.\n",
        "\n",
        "Variational Autoencoder (VAE) memperluas autoencoder deterministik menjadi model probabilistik dan generatif. Alih-alih memetakan input ke satu titik laten, encoder menghasilkan parameter distribusi laten berupa mean ( \\mu ) dan log-variance ( \\log \\sigma^2 ). Dengan menggunakan reparameterization trick, sampling dari distribusi laten dapat dilakukan secara diferensiabel, memungkinkan backpropagation tetap berjalan.\n",
        "\n",
        "Fungsi loss VAE terdiri dari dua komponen utama:\n",
        "\n",
        "reconstruction loss, yang memastikan output tetap menyerupai input,\n",
        "latent loss, berupa KL divergence antara distribusi laten hasil encoder dan distribusi Gaussian standar.\n",
        "Kombinasi ini memaksa latent space menjadi halus dan terstruktur, sehingga memungkinkan interpolasi bermakna antar titik laten dan generasi sampel baru yang realistis."
      ],
      "metadata": {
        "id": "jXlUQQDjpCxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "# KL-based sparsity regularizer\n",
        "kl_divergence = keras.losses.kullback_leibler_divergence\n",
        "\n",
        "class KLDivergenceRegularizer(keras.regularizers.Regularizer):\n",
        "    def __init__(self, weight, target=0.1):\n",
        "        self.weight = weight\n",
        "        self.target = target\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        mean_activities = K.mean(inputs, axis=0)\n",
        "        return self.weight * (\n",
        "            kl_divergence(self.target, mean_activities) +\n",
        "            kl_divergence(1. - self.target, 1. - mean_activities)\n",
        "        )\n",
        "\n",
        "kld_reg = KLDivergenceRegularizer(weight=0.05, target=0.1)\n",
        "sparse_kl_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(300, activation=\"sigmoid\",\n",
        "                       activity_regularizer=kld_reg),\n",
        "])\n",
        "sparse_kl_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[300]),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28]),\n",
        "])\n",
        "sparse_kl_ae = keras.models.Sequential([sparse_kl_encoder, sparse_kl_decoder])\n",
        "\n",
        "# VAE components\n",
        "class Sampling(keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        mean, log_var = inputs\n",
        "        eps = K.random_normal(tf.shape(log_var))\n",
        "        return eps * K.exp(log_var / 2) + mean\n",
        "\n",
        "codings_size = 10\n",
        "inputs = keras.layers.Input(shape=[28, 28])\n",
        "z = keras.layers.Flatten()(inputs)\n",
        "z = keras.layers.Dense(150, activation=\"selu\")(z)\n",
        "z = keras.layers.Dense(100, activation=\"selu\")(z)\n",
        "codings_mean = keras.layers.Dense(codings_size)(z)\n",
        "codings_log_var = keras.layers.Dense(codings_size)(z)\n",
        "codings = Sampling()([codings_mean, codings_log_var])\n",
        "variational_encoder = keras.Model(\n",
        "    inputs=[inputs],\n",
        "    outputs=[codings_mean, codings_log_var, codings]\n",
        ")\n",
        "\n",
        "decoder_inputs = keras.layers.Input(shape=[codings_size])\n",
        "x = keras.layers.Dense(100, activation=\"selu\")(decoder_inputs)\n",
        "x = keras.layers.Dense(150, activation=\"selu\")(x)\n",
        "x = keras.layers.Dense(28 * 28, activation=\"sigmoid\")(x)\n",
        "outputs = keras.layers.Reshape([28, 28])(x)\n",
        "variational_decoder = keras.Model(\n",
        "    inputs=[decoder_inputs], outputs=[outputs]\n",
        ")\n",
        "\n",
        "_, _, codings = variational_encoder(inputs)\n",
        "reconstructions = variational_decoder(codings)\n",
        "variational_ae = keras.Model(inputs=[inputs], outputs=[reconstructions])\n",
        "\n",
        "latent_loss = -0.5 * K.sum(\n",
        "    1 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean),\n",
        "    axis=-1\n",
        ")\n",
        "variational_ae.add_loss(K.mean(latent_loss) / 784.)\n",
        "variational_ae.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "\n",
        "history = variational_ae.fit(X_train, X_train, epochs=50, batch_size=128,\n",
        "                             validation_data=(X_valid, X_valid))\n",
        "\n",
        "# Sampling new images\n",
        "codings_new = tf.random.normal(shape=[12, codings_size])\n",
        "images = variational_decoder(codings_new).numpy()"
      ],
      "metadata": {
        "id": "oKOWBRd-pGDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Basics of GAN and Custom Training Loop\n",
        "\n",
        "Generative Adversarial Network (GAN) terdiri dari dua model yang dilatih secara adversarial: generator, yang mengubah noise acak (biasanya Gaussian) menjadi data sintetis, dan discriminator, yang bertugas membedakan data asli dari data palsu. Proses training dilakukan secara bergantian dalam dua tahap pada setiap iterasi.\n",
        "\n",
        "Pertama, discriminator dilatih menggunakan batch gabungan data asli dan data palsu, dengan label masing-masing “real” dan “fake”. Kedua, generator dilatih melalui model gabungan (GAN) dengan tujuan menipu discriminator, yaitu membuat discriminator mengklasifikasikan output generator sebagai data asli. Pada tahap ini, bobot discriminator dibekukan sehingga gradien yang mengalir hanya memperbarui generator.\n",
        "\n",
        "Generator tidak pernah mengakses data asli secara langsung, melainkan hanya menerima sinyal gradien dari discriminator. Jika discriminator cukup kuat, gradien tersebut secara implisit mengandung informasi tentang struktur distribusi data asli. Namun, pelatihan GAN terkenal sulit dan rentan terhadap berbagai masalah, seperti:\n",
        "\n",
        "mode collapse, di mana generator hanya menghasilkan variasi terbatas dari data,\n",
        "ketidakstabilan training, dengan osilasi atau divergensi loss,\n",
        "sensitivitas tinggi terhadap hyperparameter dan arsitektur.\n",
        "Karena itu, GAN sering dilatih menggunakan custom training loop dan berbagai modifikasi (misalnya Wasserstein loss, gradient penalty, atau spectral normalization) untuk meningkatkan stabilitas dan kualitas hasil generatif."
      ],
      "metadata": {
        "id": "a_sfNw8SpIEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "codings_size = 30\n",
        "generator = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
        "    keras.layers.Dense(150, activation=\"selu\"),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28]),\n",
        "])\n",
        "\n",
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(150, activation=\"selu\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "])\n",
        "\n",
        "gan = keras.models.Sequential([generator, discriminator])\n",
        "\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "discriminator.trainable = False\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "\n",
        "batch_size = 32\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n",
        "\n",
        "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n",
        "    generator, discriminator = gan.layers\n",
        "    for epoch in range(n_epochs):\n",
        "        for X_batch in dataset:\n",
        "            # Phase 1: train discriminator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            generated_images = generator(noise)\n",
        "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
        "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "            discriminator.trainable = True\n",
        "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
        "\n",
        "            # Phase 2: train generator (through GAN)\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            y2 = tf.constant([[1.]] * batch_size)\n",
        "            discriminator.trainable = False\n",
        "            gan.train_on_batch(noise, y2)\n",
        "\n",
        "train_gan(gan, dataset, batch_size, codings_size)\n"
      ],
      "metadata": {
        "id": "C-h5oBLmpL9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. DCGAN and Practical GAN Tricks\n",
        "\n",
        "DCGAN (Deep Convolutional GAN) mengusulkan seperangkat prinsip arsitektur yang terbukti meningkatkan stabilitas pelatihan GAN pada data gambar. Inti pendekatannya adalah mengganti operasi pooling dengan convolution dan transposed convolution ber-stride untuk melakukan downsampling dan upsampling secara terpelajar. Hampir semua layer dilengkapi Batch Normalization untuk menstabilkan distribusi aktivasi, sementara fully connected hidden layer dihilangkan agar model bersifat sepenuhnya konvolusional.\n",
        "\n",
        "Pada sisi generator, fungsi aktivasi ReLU (atau variasinya) digunakan di hampir seluruh layer, dengan tanh di layer output. Generator menerima vektor laten berdimensi tetap (misalnya 100), memproyeksikannya menjadi feature map kecil (misalnya 7×7×128), lalu melakukan upsampling bertahap hingga mencapai resolusi target, seperti 28×28 untuk MNIST. Sebaliknya, discriminator menggunakan leaky ReLU untuk menjaga aliran gradien dan bertindak sebagai CNN klasifikasi biner yang secara bertahap menurunkan resolusi spasial.\n",
        "\n",
        "Agar konsisten dengan output tanh, citra input ke discriminator perlu di-reshape ke format [batch, height, width, channels] dan dinormalisasi ke rentang ([-1, 1]). Dropout sering ditambahkan pada discriminator sebagai regularisasi tambahan untuk mencegah overfitting terhadap data training."
      ],
      "metadata": {
        "id": "NMQnOBoPpNv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "codings_size = 100\n",
        "generator = keras.models.Sequential([\n",
        "    keras.layers.Dense(7 * 7 * 128, input_shape=[codings_size]),\n",
        "    keras.layers.Reshape([7, 7, 128]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2DTranspose(\n",
        "        64, kernel_size=5, strides=2, padding=\"same\", activation=\"selu\"\n",
        "    ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2DTranspose(\n",
        "        1, kernel_size=5, strides=2, padding=\"same\", activation=\"tanh\"\n",
        "    ),\n",
        "])\n",
        "\n",
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(\n",
        "        64, kernel_size=5, strides=2, padding=\"same\",\n",
        "        activation=keras.layers.LeakyReLU(0.2),\n",
        "        input_shape=[28, 28, 1],\n",
        "    ),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Conv2D(\n",
        "        128, kernel_size=5, strides=2, padding=\"same\",\n",
        "        activation=keras.layers.LeakyReLU(0.2),\n",
        "    ),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "])\n",
        "\n",
        "gan = keras.models.Sequential([generator, discriminator])\n",
        "\n",
        "# Prepare data: reshape & rescale to [-1, 1]\n",
        "X_train_dcgan = X_train.reshape(-1, 28, 28, 1) * 2. - 1.\n",
        "\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "discriminator.trainable = False\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "\n",
        "# Training loop sama seperti fungsi train_gan di atas, hanya mengganti X_train_dcgan\n"
      ],
      "metadata": {
        "id": "xlGKThcRpP8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Advanced GANs: Progressive Growing, StyleGAN, and Training Tricks\n",
        "\n",
        "Untuk menghasilkan gambar beresolusi tinggi secara stabil, diperkenalkan teknik Progressive Growing of GANs, di mana pelatihan dimulai dari resolusi sangat kecil (misalnya 4×4) dan secara bertahap ditingkatkan ke resolusi yang lebih besar (8×8, 16×16, dan seterusnya). Layer baru ditambahkan secara perlahan menggunakan mekanisme fade-in, yaitu interpolasi antara output jaringan lama dan jaringan yang diperluas dengan koefisien ( \\alpha ), sehingga transisi resolusi berlangsung mulus dan stabil.\n",
        "\n",
        "Beberapa teknik tambahan turut digunakan untuk meningkatkan stabilitas dan keragaman sampel, seperti minibatch standard deviation layer untuk mendorong variasi antar sampel, equalized learning rate untuk menyeimbangkan skala bobot antar layer, serta pixelwise normalization pada generator.\n",
        "\n",
        "StyleGAN melangkah lebih jauh dengan memisahkan latent code awal ( z ) dari representasi gaya ( w ) melalui sebuah mapping network berbasis MLP. Representasi gaya ini kemudian disuntikkan ke setiap level resolusi dalam synthesis network menggunakan Adaptive Instance Normalization (AdaIN), memungkinkan kontrol terpisah terhadap atribut global dan lokal gambar. Selain itu, noise acak eksplisit ditambahkan pada tiap level untuk memodelkan detail stokastik seperti tekstur kulit atau helai rambut.\n",
        "\n",
        "Teknik style mixing menggunakan lebih dari satu latent code pada level resolusi yang berbeda, sehingga jaringan tidak mempelajari ketergantungan semu antar level dan terdorong untuk melokalisasi fitur secara semantik. Pendekatan-pendekatan ini menghasilkan gambar wajah dengan kualitas sangat tinggi, memungkinkan interpolasi laten yang halus dan manipulasi semantik seperti perubahan ekspresi, usia, atau atribut visual tertentu.\n",
        "\n",
        "Bab ini juga menyinggung berbagai pengembangan lain, termasuk conditional GAN, experience replay, dan mini-batch discrimination, serta pentingnya evaluasi kualitas dan diversitas hasil generatif. Meskipun kemajuannya signifikan, pelatihan GAN tetap merupakan area riset yang menantang dan terus berkembang."
      ],
      "metadata": {
        "id": "srOkVqtppRld"
      }
    }
  ]
}